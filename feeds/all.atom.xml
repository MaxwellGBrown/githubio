<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>MaxwellGBrown</title><link href="/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>/</id><updated>2021-05-26T00:00:00-05:00</updated><entry><title>Everything is MapReduce</title><link href="/everything-is-mapreduce.html" rel="alternate"></link><published>2021-05-26T00:00:00-05:00</published><updated>2021-05-26T00:00:00-05:00</updated><author><name>Maxwell G Brown</name></author><id>tag:None,2021-05-26:/everything-is-mapreduce.html</id><summary type="html">&lt;h1&gt;Everything is MapReduce&lt;/h1&gt;
&lt;p&gt;&lt;img alt="MapReduce. MapReduce everywhere." src="/images/mapreduce-everywhere.jpg"&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Product: "It's time to write some asynchronous data processing! We have files that may have records in the tens of thousands, and we need to categorize/label/process/onboard them into our system after submission from an HTTP request!"
(naive) Dev: "Uuh, let's just do it in â€¦&lt;/p&gt;&lt;/blockquote&gt;</summary><content type="html">&lt;h1&gt;Everything is MapReduce&lt;/h1&gt;
&lt;p&gt;&lt;img alt="MapReduce. MapReduce everywhere." src="/images/mapreduce-everywhere.jpg"&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Product: "It's time to write some asynchronous data processing! We have files that may have records in the tens of thousands, and we need to categorize/label/process/onboard them into our system after submission from an HTTP request!"
(naive) Dev: "Uuh, let's just do it in a blocking API request in a single procedural function the size of Texas?"
QA: "Hey, so the processing form doesn't work for any files larger than 500kb..."
PM: "I'll write a ticket to increase the file size!"&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It's not the first time I've had to write a system like the above and it likely won't be the last. And it won't be the first time that a developer (naively, I feel) suggests taking an incremenetal approach to implementing it first in a blocking API call that just &lt;em&gt;does everything&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;Very quickly though the team outgrows these implementations (probably because blocking API calls are a &lt;em&gt;Bad Idea&lt;/em&gt;) and then the poor dev (or even worse, his successor!) is stuck with a ticket that says something like "increase import size from 500kb" and they find themselves trying to build Rome with a hammer &amp;amp; chisel.&lt;/p&gt;
&lt;h2&gt;Let's make it right&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;This rant is about MapReduce &lt;em&gt;right&lt;/em&gt;?&lt;/strong&gt; Bear with me.&lt;/p&gt;
&lt;p&gt;I posit that the real problem here is starting with the &lt;em&gt;wrong&lt;/em&gt; incremental approach: building that asynchronous system into the request-response cycle should be the very FIRST thing that happens here! &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A queue with a listener that has some beefy stats? Sure okay.&lt;/li&gt;
&lt;li&gt;On-demand compute nodes to run tasks in long form fashion? Yeah, that might work.&lt;/li&gt;
&lt;li&gt;An event bus and some horizontally-scalable microservices? Sounds fun.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It doesn't ned to be entirely fleshed out, let it be an infant! Maybe you're just moving your procedural abomination downstream. Don't care, it's better now that you're not on a blocking API request.&lt;/p&gt;
&lt;p&gt;Blocking API requests are like getting groceries during COVID: you want to deliver your message and get the hell out. Any time you spend standing in line should be making you anxious about the things happening around you.&lt;/p&gt;
&lt;p&gt;We probably skip away from this implementation happy that we've built something cool and loosened the valve on the future featurres we have to build into our asynchronous processing system.&lt;/p&gt;
&lt;h2&gt;Okay what next?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Where is the MapReduce?&lt;/strong&gt; &lt;em&gt;Yeah yeah&lt;/em&gt; I'm getting there.&lt;/p&gt;
&lt;p&gt;We have our nice pretty custom asynchronous data processing tooling, and it's way better than what we had before. I mean &lt;em&gt;way&lt;/em&gt; better. We can actually add features to it without worry that "rEqUeStS wILl TiMe OuT!". &lt;/p&gt;
&lt;p&gt;We've introduced more infrastructure overhead (after all, we &lt;em&gt;did&lt;/em&gt; solve this problem with more infrastructure). The solution is pretty custom, lets say that there's 5 steps in our flow and each step transforms and does some processing against the data. Let's pencil it out:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Turn XLSX rows into JSON data&lt;/li&gt;
&lt;li&gt;Read JSON records for an ID to insert/update into our system&lt;/li&gt;
&lt;li&gt;Read certain fields in said records for URLs of images&lt;/li&gt;
&lt;li&gt;Download said images&lt;/li&gt;
&lt;li&gt;Insert/update database with some light processing/transformed of values (e.g. whitespace trimming)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;...and maybe to do this we have a workflow manager that manages moving between steps for us! When 1 is done, do 2. When 2 is done do 3. Do I need to do step 4? No? Skip to 5.&lt;/p&gt;
&lt;p&gt;All the while, dropping our intermediate data somewhere so we can both pick it up at the next step or audit it after the fact.&lt;/p&gt;
&lt;h2&gt;In case you haven't noticed yet...&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;This post is about MapReduce now!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="It's all MapReduce? Always has been." src="/images/mapreduce-always-has-been.jpg"&gt;&lt;/p&gt;
&lt;p&gt;We did all this work just to implement a glorified MapReduce!&lt;/p&gt;
&lt;p&gt;And we &lt;em&gt;haaaate&lt;/em&gt; unnecessary work. Why build something custom when you can worry about less and finger-point at other vendors when your stuff isn't working right?&lt;/p&gt;
&lt;p&gt;Here's the hot-take of the day: &lt;strong&gt;All data processing is just glorified MapReduce&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Why do we even bother building our own things when we have these solutions that are hand-tailored to ripping apart and processing large swaths of data!? Would we have not done ourselves a service by starting directly with Hadoop, or a mature MapReduce-ing solution?&lt;/p&gt;
&lt;h2&gt;I don't see it yet&lt;/h2&gt;
&lt;p&gt;It's in the name. MapReduce is two main parts:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Map&lt;/strong&gt; initial data into keys that correspond to how we're processing the data&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reduce&lt;/strong&gt; mapped data into "organized" data that we want to work with&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;...and if we want to get into specifics those two actually have other steps to talk about:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Map&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Input
     Give the initial input&lt;/li&gt;
&lt;li&gt;Split
     Split initial data into processable chunks&lt;/li&gt;
&lt;li&gt;Map
     Take a chunk and key the records you want from it&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reduce&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Shuffle
     Across the chunks, organize data into logical groups&lt;/li&gt;
&lt;li&gt;Reduce
     Turn the logical groups into new data&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With those enumerated, it's a lot easier to see how our problem statement fits so well into this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Turn XLSX rows into JSON data&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Input&lt;/strong&gt; XLSX file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Split&lt;/strong&gt; XLSX rows into JSON data&lt;/li&gt;
&lt;li&gt;Read JSON records for an ID to insert/update into our system&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Map&lt;/strong&gt; JSON records into keys&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Shuffle&lt;/strong&gt; records into separate "Inserts" and "Update" groups&lt;/li&gt;
&lt;li&gt;Read certain fields in said records for URLs of images
   (The ordered list is doing me a disservice now, since this will likely happen simultaneous to 2, but the show must go on)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Map&lt;/strong&gt; fields with URLs&lt;/li&gt;
&lt;li&gt;Download said images&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reduce&lt;/strong&gt; URLs to new hosted location&lt;/li&gt;
&lt;li&gt;Insert/update database with some light processing/transformed of values (e.g. whitespace trimming)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reduce&lt;/strong&gt; to new records&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Did I mention that each of these steps saves the intermediate data, so we can audit between steps? &lt;/p&gt;
&lt;p&gt;I've built systems similar to this thrice over at my job, and whenever I take a step back to admire my handiwork I end up thinking to myself:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Did I just build a glorified MapReduce?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Who are you? Rey. Rey MapReduce" src="/images/rey-mapreduce.jpg"&gt;&lt;/p&gt;
&lt;h2&gt;Confession/Disclaimer&lt;/h2&gt;
&lt;p&gt;I have no idea what I'm talking about. I've never actually used Hadoop before, nor any of the othere "MapReducers" I could find in a 3-minute google sesh (Apache Spark, Apache Storm, BigQuery, Disco).&lt;/p&gt;
&lt;p&gt;But here I am with the confession that I've ~wasted~ spent plenty of time implementing solutions that would likely fit into the category of "Hadoop Alternative".&lt;/p&gt;
&lt;p&gt;So, perhaps this rant was more for &lt;em&gt;me&lt;/em&gt; than any reader:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Maybe I should look into Hadoop or it's alternatives?&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;</content><category term="rants"></category></entry><entry><title>Hello Pelican</title><link href="/hello-pelican.html" rel="alternate"></link><published>2021-05-25T00:00:00-05:00</published><updated>2021-05-25T00:00:00-05:00</updated><author><name>Maxwell G Brown</name></author><id>tag:None,2021-05-25:/hello-pelican.html</id><content type="html">&lt;h1&gt;Hello Pelican&lt;/h1&gt;
&lt;p&gt;This is a markdown file that Pelican turns into blog posts (or something? lets find out).&lt;/p&gt;
&lt;p&gt;Shamelessly followed &lt;a href="https://opensource.com/article/19/5/run-your-blog-github-pages-python"&gt;this blog post&lt;/a&gt; to see what the result is.&lt;/p&gt;
&lt;p&gt;&lt;img alt="A picture of a pelican" src="/images/pelican.jpg"&gt;&lt;/p&gt;</content><category term="posts"></category></entry></feed>