<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <title>MaxwellGBrown - rants</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="MaxwellGBrown Atom Feed" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">MaxwellGBrown</a></h1>
                <nav><ul>
                    <li><a href="/category/posts.html">posts</a></li>
                    <li class="active"><a href="/category/rants.html">rants</a></li>
                </ul></nav>
        </header><!-- /#banner -->

            <aside id="featured" class="body">
                <article>
                    <h1 class="entry-title"><a href="/everything-is-mapreduce.html">Everything is MapReduce</a></h1>
<footer class="post-info">
        <abbr class="published" title="2021-05-26T00:00:00-05:00">
                Published: Wed 26 May 2021
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/maxwell-g-brown.html">Maxwell G Brown</a>
        </address>
<p>In <a href="/category/rants.html">rants</a>.</p>

</footer><!-- /.post-info --><h1>Everything is MapReduce</h1>
<p><img alt="MapReduce. MapReduce everywhere." src="/images/mapreduce-everywhere.jpg"></p>
<blockquote>
<p>Product: "It's time to write some asynchronous data processing! We have files that may have records in the tens of thousands, and we need to categorize/label/process/onboard them into our system after submission from an HTTP request!"</p>
<p>(naive) Dev: "Uuh, let's just do it in a blocking API request in a single procedural function the size of Texas?"</p>
<p>QA: "Hey, so the processing form doesn't work for any files larger than 500kb..."</p>
<p>PM: "I'll write a ticket to increase the file size!"</p>
</blockquote>
<p>It's not the first time I've had to write a system like the above and it likely won't be the last. And it won't be the first time that a developer (naively, I feel) suggests taking an incremenetal approach to implementing it first in a blocking API call that just <em>does everything</em>. </p>
<p>Very quickly though the team outgrows these implementations (probably because blocking API calls are a <em>Bad Idea</em>) and then the poor dev (or even worse, his successor!) is stuck with a ticket that says something like "increase import size from 500kb" and they find themselves trying to build Rome with a hammer &amp; chisel.</p>
<h2>Let's make it right</h2>
<p><strong>This rant is about MapReduce <em>right</em>?</strong> Bear with me.</p>
<p>I posit that the real problem here is starting with the <em>wrong</em> incremental approach: building that asynchronous system into the request-response cycle should be the very FIRST thing that happens here! </p>
<ul>
<li>A queue with a listener that has some beefy stats? Sure okay.</li>
<li>On-demand compute nodes to run tasks in long form fashion? Yeah, that might work.</li>
<li>An event bus and some horizontally-scalable microservices? Sounds fun.</li>
</ul>
<p>It doesn't ned to be entirely fleshed out, let it be an infant! Maybe you're just moving your procedural abomination downstream. Don't care, it's better now that you're not on a blocking API request.</p>
<p>Blocking API requests are like getting groceries during COVID: you want to deliver your message and get the hell out. Any time you spend standing in line should be making you anxious about the things happening around you.</p>
<p>We probably skip away from this implementation happy that we've built something cool and loosened the valve on the future featurres we have to build into our asynchronous processing system.</p>
<h2>Okay what next?</h2>
<p><strong>Where is the MapReduce?</strong> <em>Yeah yeah</em> I'm getting there.</p>
<p>We have our nice pretty custom asynchronous data processing tooling, and it's way better than what we had before. I mean <em>way</em> better. We can actually add features to it without worry that "rEqUeStS wILl TiMe OuT!". </p>
<p>We've introduced more infrastructure overhead (after all, we <em>did</em> solve this problem with more infrastructure). The solution is pretty custom, lets say that there's 5 steps in our flow and each step transforms and does some processing against the data. Let's pencil it out:</p>
<ol>
<li>Turn XLSX rows into JSON data</li>
<li>Read JSON records for an ID to insert/update into our system</li>
<li>Read certain fields in said records for URLs of images</li>
<li>Download said images</li>
<li>Insert/update database with some light processing/transformed of values (e.g. whitespace trimming)</li>
</ol>
<p>...and maybe to do this we have a workflow manager that manages moving between steps for us! When 1 is done, do 2. When 2 is done do 3. Do I need to do step 4? No? Skip to 5.</p>
<p>All the while, dropping our intermediate data somewhere so we can both pick it up at the next step or audit it after the fact.</p>
<h2>In case you haven't noticed yet...</h2>
<p><strong>This post is about MapReduce now!</strong></p>
<p><img alt="It's all MapReduce? Always has been." src="/images/mapreduce-always-has-been.jpg"></p>
<p>We did all this work just to implement a glorified MapReduce!</p>
<p>And we <em>haaaate</em> unnecessary work. Why build something custom when you can worry about less and finger-point at other vendors when your stuff isn't working right?</p>
<p>Here's the hot-take of the day: <strong>All data processing is just glorified MapReduce</strong>.</p>
<p>Why do we even bother building our own things when we have these solutions that are hand-tailored to ripping apart and processing large swaths of data!? Would we have not done ourselves a service by starting directly with Hadoop, or a mature MapReduce-ing solution?</p>
<h2>I don't see it yet</h2>
<p>It's in the name. MapReduce is two main parts:</p>
<ol>
<li><strong>Map</strong> initial data into keys that correspond to how we're processing the data</li>
<li><strong>Reduce</strong> mapped data into "organized" data that we want to work with</li>
</ol>
<p>...and if we want to get into specifics those two actually have other steps to talk about:</p>
<ol>
<li><strong>Map</strong></li>
<li>Input
     Give the initial input</li>
<li>Split
     Split initial data into processable chunks</li>
<li>Map
     Take a chunk and key the records you want from it</li>
<li><strong>Reduce</strong></li>
<li>Shuffle
     Across the chunks, organize data into logical groups</li>
<li>Reduce
     Turn the logical groups into new data</li>
</ol>
<p>With those enumerated, it's a lot easier to see how our problem statement fits so well into this:</p>
<ol>
<li>Turn XLSX rows into JSON data</li>
<li><strong>Input</strong> XLSX file</li>
<li><strong>Split</strong> XLSX rows into JSON data</li>
<li>Read JSON records for an ID to insert/update into our system</li>
<li><strong>Map</strong> JSON records into keys</li>
<li><strong>Shuffle</strong> records into separate "Inserts" and "Update" groups</li>
<li>Read certain fields in said records for URLs of images
   (The ordered list is doing me a disservice now, since this will likely happen simultaneous to 2, but the show must go on)</li>
<li><strong>Map</strong> fields with URLs</li>
<li>Download said images</li>
<li><strong>Reduce</strong> URLs to new hosted location</li>
<li>Insert/update database with some light processing/transformed of values (e.g. whitespace trimming)</li>
<li><strong>Reduce</strong> to new records</li>
</ol>
<p>Did I mention that each of these steps saves the intermediate data, so we can audit between steps? </p>
<p>I've built systems similar to this thrice over at my job, and whenever I take a step back to admire my handiwork I end up thinking to myself:</p>
<p><strong>Did I just build a glorified MapReduce?</strong></p>
<p><img alt="Who are you? Rey. Rey MapReduce" src="/images/rey-mapreduce.jpg"></p>
<h2>Confession/Disclaimer</h2>
<p>I have no idea what I'm talking about. I've never actually used Hadoop before, nor any of the othere "MapReducers" I could find in a 3-minute google sesh (Apache Spark, Apache Storm, BigQuery, Disco).</p>
<p>But here I am with the confession that I've ~wasted~ spent plenty of time implementing solutions that would likely fit into the category of "Hadoop Alternative".</p>
<p>So, perhaps this rant was more for <em>me</em> than any reader:</p>
<blockquote>
<p><em>Maybe I should look into Hadoop or it's alternatives?</em></p>
</blockquote>                </article>
            </aside><!-- /#featured -->
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>links</h2>
                        <ul>
                            <li><a href="https://getpelican.com/">Pelican</a></li>
                            <li><a href="https://www.python.org/">Python.org</a></li>
                            <li><a href="https://palletsprojects.com/p/jinja/">Jinja2</a></li>
                            <li><a href="#">You can modify those links in your config file</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>
                            <li><a href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate">atom feed</a></li>

                            <li><a href="#">You can add links in your config file</a></li>
                            <li><a href="#">Another social link</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>